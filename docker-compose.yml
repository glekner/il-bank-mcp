# Global anchors / extension fields to promote DRY configuration
x-service-defaults: &service-defaults # Common runtime settings for all services
  restart: unless-stopped
  env_file:
    - .env
  environment:
    NODE_ENV: production
    DATABASE_PATH: /app/data/bank.db
    PUPPETEER_EXECUTABLE_PATH: /usr/bin/chromium-browser
    PUPPETEER_ARGS: --no-sandbox,--disable-setuid-sandbox,--disable-dev-shm-usage
  networks:
    - bank-network
  security_opt:
    - seccomp=unconfined
  cap_add:
    - SYS_ADMIN

services:
  # Scraper service - runs the bank scraping backend
  scraper:
    <<: *service-defaults
    build:
      context: .
      dockerfile: Dockerfile
      target: scraper
    container_name: bank-scraper
    volumes:
      - bank-data:/app/data # Persist scraped DB between container restarts
      - ./packages/scraper/logs:/app/packages/scraper/logs
    command: ["node", "dist/scheduler.js"]
    healthcheck:
      test: ["CMD", "node", "-e", "process.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # MCP Server - Model Context Protocol server
  mcp-server:
    <<: *service-defaults
    build:
      context: .
      dockerfile: Dockerfile
      target: mcp-server
    container_name: bank-mcp-server
    volumes:
      - bank-data:/app/data # Read-write access to DB for forced scraping
    depends_on:
      scraper:
        condition: service_healthy
    stdin_open: true
    tty: true
    # MCP servers communicate via stdio, so we don't expose ports
    # The server will be accessed via docker exec or docker run commands

networks:
  bank-network:
    driver: bridge
    name: bank-assistant-network

volumes:
  bank-data:
    driver: local
